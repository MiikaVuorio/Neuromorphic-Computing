{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0820b0ad",
   "metadata": {},
   "source": [
    "# STDP learning for classifying touch input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64f9a9",
   "metadata": {},
   "source": [
    "Based on the architecture presented in Peter U. Diehl's seminal 2015 work: \"Unsupervised learning of digit recognition using spike-timing-dependent plasticity\", (https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full, https://github.com/peter-u-diehl/stdp-mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55960cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increasing width of notebook, because of long lines\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fe7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brian2 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (1.25.0)\n",
      "Requirement already satisfied: setuptools>=24.2 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (65.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (22.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (9.0.0)\n",
      "Requirement already satisfied: sympy>=1.2 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (1.11.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (3.0.9)\n",
      "Requirement already satisfied: jinja2>=2.7 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2) (3.1.2)\n",
      "Requirement already satisfied: cython>=0.29 in c:\\users\\vuoriom3\\appdata\\roaming\\python\\python310\\site-packages (from brian2) (0.29.35)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2>=2.7->brian2) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy>=1.2->brian2) (1.2.1)\n",
      "Collecting brian2tools\n",
      "  Downloading brian2tools-0.3-py2.py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.9/87.9 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting markdown-strings\n",
      "  Downloading markdown_strings-3.3.0-py2.py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: brian2>=2.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2tools) (2.5.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2tools) (65.6.3)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in c:\\users\\vuoriom3\\appdata\\roaming\\python\\python310\\site-packages (from brian2tools) (3.7.1)\n",
      "Collecting pylems>=0.4.9\n",
      "  Downloading PyLEMS-0.6.4-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.0/67.0 kB ? eta 0:00:00\n",
      "Collecting libNeuroML>=0.2.18\n",
      "  Downloading libNeuroML-0.5.3-py3-none-any.whl (354 kB)\n",
      "     ------------------------------------- 354.6/354.6 kB 21.5 MB/s eta 0:00:00\n",
      "Collecting setuptools-scm\n",
      "  Downloading setuptools_scm-7.1.0-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.8/43.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (1.25.0)\n",
      "Requirement already satisfied: sympy>=1.2 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (1.11.1)\n",
      "Requirement already satisfied: cython>=0.29 in c:\\users\\vuoriom3\\appdata\\roaming\\python\\python310\\site-packages (from brian2>=2.0->brian2tools) (0.29.35)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (3.0.9)\n",
      "Requirement already satisfied: jinja2>=2.7 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (3.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (22.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from brian2>=2.0->brian2tools) (9.0.0)\n",
      "Requirement already satisfied: tables>=3.3.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from libNeuroML>=0.2.18->brian2tools) (3.7.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from libNeuroML>=0.2.18->brian2tools) (2.8.4)\n",
      "Requirement already satisfied: six in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from libNeuroML>=0.2.18->brian2tools) (1.16.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from libNeuroML>=0.2.18->brian2tools) (4.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.3.1->brian2tools) (2.8.2)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from setuptools-scm->brian2tools) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from setuptools-scm->brian2tools) (4.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2>=2.7->brian2>=2.0->brian2tools) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy>=1.2->brian2>=2.0->brian2tools) (1.2.1)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in c:\\users\\vuoriom3\\appdata\\local\\anaconda3\\lib\\site-packages (from tables>=3.3.0->libNeuroML>=0.2.18->brian2tools) (2.8.4)\n",
      "Installing collected packages: markdown-strings, setuptools-scm, pylems, libNeuroML, brian2tools\n",
      "Successfully installed brian2tools-0.3 libNeuroML-0.5.3 markdown-strings-3.3.0 pylems-0.6.4 setuptools-scm-7.1.0\n"
     ]
    }
   ],
   "source": [
    "#brian2 installation!\n",
    "!python -m pip install brian2\n",
    "!python -m pip install brian2tools\n",
    "#!conda install -c conda-forge brian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5413e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import statements\n",
    "import numpy as np\n",
    "import matplotlib.cm as cmap\n",
    "import time\n",
    "import os.path\n",
    "import scipy \n",
    "import pickle\n",
    "#import brian_no_units  #import it to deactivate unit checking --> This should NOT be done for testing/debugging \n",
    "import brian2 as b\n",
    "from struct import unpack\n",
    "from brian2 import *\n",
    "from brian2tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39e035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing random things\n",
    "19*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89982739",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading data into relevant np arrays\n",
    "\n",
    "# specify the location of the data\n",
    "notebook_path = os.path.abspath(\"BRIAN_DIEHL_COOK_2015.ipynb\")\n",
    "#MNIST_data_path = os.path.join(os.path.dirname(notebook_path), \"Datasets\\\\\")\n",
    "touch_data_vec_path = os.path.join(os.path.dirname(notebook_path), \"Datasets\\\\Vector-data-of-A-Z\\\\\")\n",
    "\n",
    "\n",
    "\n",
    "def get_labeled_touch_vec_data(first_file_num, last_file_num, data_path):\n",
    "    \n",
    "    N = last_file_num - (first_file_num - 1)\n",
    "    tot_N = N * 26\n",
    "    x = np.zeros((tot_N, 5))\n",
    "    y = np.zeros((tot_N, 1))\n",
    "    \n",
    "    pos = 0\n",
    "    for file_num in range(first_file_num, last_file_num+1):\n",
    "        file_name = 'Training' + str(file_num) + '.txt'\n",
    "        file_path = data_path + file_name\n",
    "        touch_vecs = open(file_path)\n",
    "        for letter in range(26):\n",
    "            y[letter + pos] = (ord(touch_vecs.read(1)) - 65)\n",
    "            \n",
    "            touch_vecs.read(1)\n",
    "        x[pos:(pos+26), :] = np.transpose(np.loadtxt(file_path, skiprows=1))\n",
    "        \n",
    "        \n",
    "        pos += 26\n",
    "    data = {'x': x, 'y': y}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128a25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------ \n",
    "# functions (from original for the most part)\n",
    "#------------------------------------------------------------------------------     \n",
    "\n",
    "def get_labeled_data(picklename, bTrain = True):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('%s.pickle' % picklename):\n",
    "        data = pickle.load(open('%s.pickle' % picklename))\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode\n",
    "        if bTrain:\n",
    "            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "    \n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        for i in range(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in range(cols)]  for unused_row in range(rows) ]\n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "            \n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(\"%s.pickle\" % picklename, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def get_matrix_from_file(fileName):\n",
    "    offset = len(ending) + 4\n",
    "    if fileName[-4-offset] == 'X':\n",
    "        n_src = n_input                \n",
    "    else:\n",
    "        if fileName[-3-offset]=='e':\n",
    "            n_src = n_e\n",
    "        else:\n",
    "            n_src = n_i\n",
    "    if fileName[-1-offset]=='e':\n",
    "        n_tgt = n_e\n",
    "    else:\n",
    "        n_tgt = n_i\n",
    "    readout = np.load(fileName)\n",
    "    print(readout.shape, fileName)\n",
    "    value_arr = np.zeros((n_src, n_tgt))\n",
    "    if not readout.shape == (0,):\n",
    "        value_arr[np.int32(readout[:,0]), np.int32(readout[:,1])] = readout[:,2]\n",
    "    return value_arr\n",
    "\n",
    "\n",
    "def save_connections(ending = ''):\n",
    "    print('save connections')\n",
    "    for connName in save_conns:\n",
    "        connMatrix = connections[connName][:]\n",
    "#         connListSparse = ([(i,j[0],j[1]) for i in range(connMatrix.shape[0]) for j in zip(connMatrix.rowj[i],connMatrix.rowdata[i])])\n",
    "        connListSparse = ([(i,j,connMatrix[i,j]) for i in range(connMatrix.shape[0]) for j in range(connMatrix.shape[1]) ])\n",
    "        np.save(data_path + 'weights/' + connName + ending, connListSparse)\n",
    "\n",
    "def save_theta(ending = ''):\n",
    "    print('save theta')\n",
    "    for pop_name in population_names:\n",
    "        np.save(data_path + 'weights/theta_' + pop_name + ending, neuron_groups[pop_name + 'e'].theta)\n",
    "\n",
    "def normalize_weights():\n",
    "    for connName in connections:\n",
    "        if connName[1] == 'e' and connName[3] == 'e':\n",
    "            connection = connections[connName][:]\n",
    "            temp_conn = np.copy(connection)\n",
    "            colSums = np.sum(temp_conn, axis = 0)\n",
    "            colFactors = weight['ee_input']/colSums\n",
    "            for j in range(n_e):#\n",
    "                connection[:,j] *= colFactors[j]\n",
    "            \n",
    "def get_2d_input_weights():\n",
    "    name = 'XeAe'\n",
    "    weight_matrix = np.zeros((n_input, n_e))\n",
    "    n_e_sqrt = int(np.sqrt(n_e))\n",
    "    n_in_sqrt = int(np.sqrt(n_input))\n",
    "    num_values_col = n_e_sqrt*n_in_sqrt\n",
    "    num_values_row = num_values_col\n",
    "    rearranged_weights = np.zeros((num_values_col, num_values_row))\n",
    "    connMatrix = connections[name][:]\n",
    "    weight_matrix = np.copy(connMatrix)\n",
    "        \n",
    "    for i in range(n_e_sqrt):\n",
    "        for j in range(n_e_sqrt):\n",
    "                rearranged_weights[i*n_in_sqrt : (i+1)*n_in_sqrt, j*n_in_sqrt : (j+1)*n_in_sqrt] = \\\n",
    "                    weight_matrix[:, i + j*n_e_sqrt].reshape((n_in_sqrt, n_in_sqrt))\n",
    "    return rearranged_weights\n",
    "\n",
    "\n",
    "def plot_2d_input_weights():\n",
    "    name = 'XeAe'\n",
    "    weights = get_2d_input_weights()\n",
    "    fig = b.figure(fig_num, figsize = (18, 18))\n",
    "    im2 = b.imshow(weights, interpolation = \"nearest\", vmin = 0, vmax = wmax_ee, cmap = cmap.get_cmap('hot_r'))\n",
    "    b.colorbar(im2)\n",
    "    b.title('weights of connection' + name)\n",
    "    fig.canvas.draw()\n",
    "    return im2, fig\n",
    "    \n",
    "def update_2d_input_weights(im, fig):\n",
    "    weights = get_2d_input_weights()\n",
    "    im.set_array(weights)\n",
    "    fig.canvas.draw()\n",
    "    return im\n",
    "\n",
    "def get_current_performance(performance, current_example_num):\n",
    "    current_evaluation = int(current_example_num/update_interval)\n",
    "    start_num = current_example_num - update_interval\n",
    "    end_num = current_example_num\n",
    "    difference = outputNumbers[start_num:end_num, 0] - input_numbers[start_num:end_num]\n",
    "    correct = len(np.where(difference == 0)[0])\n",
    "    performance[current_evaluation] = correct / float(update_interval) * 100\n",
    "    return performance\n",
    "\n",
    "def plot_performance(fig_num):\n",
    "    num_evaluations = int(num_examples/update_interval)\n",
    "    time_steps = range(0, num_evaluations)\n",
    "    performance = np.zeros(num_evaluations)\n",
    "    fig = b.figure(fig_num, figsize = (5, 5))\n",
    "    fig_num += 1\n",
    "    ax = fig.add_subplot(111)\n",
    "    im2, = ax.plot(time_steps, performance) #my_cmap\n",
    "    b.ylim(ymax = 100)\n",
    "    b.title('Classification performance')\n",
    "    fig.canvas.draw()\n",
    "    return im2, performance, fig_num, fig\n",
    "\n",
    "def update_performance_plot(im, performance, current_example_num, fig):\n",
    "    performance = get_current_performance(performance, current_example_num)\n",
    "    im.set_ydata(performance)\n",
    "    fig.canvas.draw()\n",
    "    return im, performance\n",
    "    \n",
    "def get_recognized_number_ranking(assignments, spike_rates):\n",
    "    summed_rates = [0] * 10\n",
    "    num_assignments = [0] * 10\n",
    "    for i in range(10):\n",
    "        num_assignments[i] = len(np.where(assignments == i)[0])\n",
    "        if num_assignments[i] > 0:\n",
    "            summed_rates[i] = np.sum(spike_rates[assignments == i]) / num_assignments[i]\n",
    "    return np.argsort(summed_rates)[::-1]\n",
    "\n",
    "def get_new_assignments(result_monitor, input_numbers):\n",
    "    assignments = np.zeros(n_e)\n",
    "    input_nums = np.asarray(input_numbers)\n",
    "    maximum_rate = [0] * n_e    \n",
    "    for j in range(10):\n",
    "        num_assignments = len(np.where(input_nums == j)[0])\n",
    "        if num_assignments > 0:\n",
    "            rate = np.sum(result_monitor[input_nums == j], axis = 0) / num_assignments\n",
    "        for i in range(n_e):\n",
    "            if rate[i] > maximum_rate[i]:\n",
    "                maximum_rate[i] = rate[i]\n",
    "                assignments[i] = j\n",
    "    return assignments\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a3522b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time needed to load training set: 0.11838030815124512\n",
      "time needed to load test set: 0.005983591079711914\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------ \n",
    "# load touch vec data\n",
    "#------------------------------------------------------------------------------\n",
    "start = time.time()\n",
    "training = get_labeled_touch_vec_data(1,19,touch_data_vec_path)\n",
    "end = time.time()\n",
    "print('time needed to load training set:', end - start)\n",
    " \n",
    "start = time.time()\n",
    "testing = get_labeled_touch_vec_data(20,20,touch_data_vec_path)\n",
    "end = time.time()\n",
    "print('time needed to load test set:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae07fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------ \n",
    "# set parameters and equations\n",
    "#------------------------------------------------------------------------------\n",
    "test_mode = False\n",
    "\n",
    "### Depracated method of setting preferences in brian1\n",
    "\n",
    "# b.set_global_preferences( \n",
    "#                         defaultclock = b.Clock(dt=0.5*b.ms), # The default clock to use if none is provided or defined in any enclosing scope.\n",
    "#                         useweave = True, # Defines whether or not functions should use inlined compiled C code where defined.\n",
    "#                         gcc_options = ['-ffast-math -march=native'],  # Defines the compiler switches passed to the gcc compiler. \n",
    "#                         #For gcc versions 4.2+ we recommend using -march=native. By default, the -ffast-math optimizations are turned on \n",
    "#                         usecodegen = True,  # Whether or not to use experimental code generation support.\n",
    "#                         usecodegenweave = True,  # Whether or not to use C with experimental code generation support.\n",
    "#                         usecodegenstateupdate = True,  # Whether or not to use experimental code generation support on state updaters.\n",
    "#                         usecodegenthreshold = False,  # Whether or not to use experimental code generation support on thresholds.\n",
    "#                         usenewpropagate = True,  # Whether or not to use experimental new C propagation functions.\n",
    "#                         usecstdp = True,  # Whether or not to use experimental new C STDP.\n",
    "#                        ) \n",
    "\n",
    "### Setting preferences in brian2 (likely nothing needs to be set)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "data_path = './'\n",
    "if test_mode:\n",
    "    weight_path = data_path + 'weights/'\n",
    "    num_examples = 26\n",
    "    use_testing_set = True\n",
    "    do_plot_performance = False\n",
    "    record_spikes = True\n",
    "    ee_STDP_on = False\n",
    "    update_interval = num_examples\n",
    "else:\n",
    "    weight_path = data_path + 'random/'  \n",
    "    num_examples = (19 * 26) * 30 #Thirty repetitions with the data (arbitrary choice) \n",
    "    use_testing_set = False\n",
    "    do_plot_performance = True\n",
    "    #Huh? record spikes true nonetheless, what's the point\n",
    "    if num_examples <= (19 * 26):    \n",
    "        record_spikes = True\n",
    "    else:\n",
    "        record_spikes = True\n",
    "    ee_STDP_on = True\n",
    "\n",
    "\n",
    "ending = ''\n",
    "n_input = 5\n",
    "n_e = 400\n",
    "n_i = n_e \n",
    "single_example_time = 0.35 * b.second #\n",
    "resting_time = 0.15 * b.second\n",
    "runtime = num_examples * (single_example_time + resting_time)\n",
    "if num_examples <= 100:    \n",
    "    update_interval = num_examples\n",
    "    weight_update_interval = 20\n",
    "else:\n",
    "    update_interval = 100\n",
    "    weight_update_interval = 1 ## I randomly just decreased all these numbers by two orders of magnitude\n",
    "if num_examples <= 494:    \n",
    "    save_connections_interval = 100\n",
    "else:\n",
    "    save_connections_interval = 100\n",
    "    update_interval = 100\n",
    "\n",
    "v_rest_e = -65. * b.mV \n",
    "v_rest_i = -60. * b.mV \n",
    "v_reset_e = -65. * b.mV\n",
    "v_reset_i = -45. * b.mV\n",
    "v_thresh_e = -52. * b.mV\n",
    "v_thresh_i = -40. * b.mV\n",
    "refrac_e = 5. * b.ms\n",
    "refrac_i = 2. * b.ms\n",
    "\n",
    "conn_structure = 'dense'\n",
    "weight = {}\n",
    "delay = {}\n",
    "input_population_names = ['X']\n",
    "population_names = ['A']\n",
    "input_connection_names = ['XA']\n",
    "save_conns = ['XeAe']\n",
    "input_conn_names = ['ee_input'] \n",
    "recurrent_conn_names = ['ei', 'ie']\n",
    "weight['ee_input'] = 78.\n",
    "delay['ee_input'] = (0*b.ms,10*b.ms)\n",
    "delay['ei_input'] = (0*b.ms,5*b.ms)\n",
    "input_intensity = 64.\n",
    "start_input_intensity = input_intensity\n",
    "\n",
    "tc_pre_ee = 20*b.ms\n",
    "tc_post_1_ee = 20*b.ms\n",
    "tc_post_2_ee = 40*b.ms\n",
    "nu_ee_pre =  0.0001      # learning rate\n",
    "nu_ee_post = 0.01       # learning rate\n",
    "wmax_ee = 1.0\n",
    "exp_ee_pre = 0.2\n",
    "exp_ee_post = exp_ee_pre\n",
    "STDP_offset = 0.4\n",
    "\n",
    "if test_mode:\n",
    "    scr_e = 'v = v_reset_e; timer = 0*ms'\n",
    "else:\n",
    "    tc_theta = 1e7 * b.ms\n",
    "    theta_plus_e = 0.05 * b.mV\n",
    "    scr_e = 'v = v_reset_e; theta += theta_plus_e; timer = 0*ms'\n",
    "offset = 20.0*b.mV\n",
    "v_thresh_e = '(v>(theta - offset + ' + str(v_thresh_e) + ')) * (timer>refrac_e)'\n",
    "\n",
    "\n",
    "neuron_eqs_e = '''\n",
    "        dv/dt = ((v_rest_e - v) + (I_synE+I_synI) / nS) / (100*ms)  : volt\n",
    "        I_synE = ge * nS *         -v                           : amp\n",
    "        I_synI = gi * nS * (-100.*mV-v)                          : amp\n",
    "        dge/dt = -ge/(1.0*ms)                                   : 1\n",
    "        dgi/dt = -gi/(2.0*ms)                                  : 1\n",
    "        '''\n",
    "if test_mode:\n",
    "    neuron_eqs_e += '\\n  theta      :volt'\n",
    "else:\n",
    "    neuron_eqs_e += '\\n  dtheta/dt = -theta / (tc_theta)  : volt'\n",
    "neuron_eqs_e += '\\n  dtimer/dt = 0.1  : second'\n",
    "\n",
    "neuron_eqs_i = '''\n",
    "        dv/dt = ((v_rest_i - v) + (I_synE+I_synI) / nS) / (10*ms)  : volt\n",
    "        I_synE = ge * nS *         -v                           : amp\n",
    "        I_synI = gi * nS * (-85.*mV-v)                          : amp\n",
    "        dge/dt = -ge/(1.0*ms)                                   : 1\n",
    "        dgi/dt = -gi/(2.0*ms)                                  : 1\n",
    "        '''\n",
    "eqs_stdp_ee = '''\n",
    "                post2before                            : 1.0\n",
    "                dpre/dt   =   -pre/(tc_pre_ee)         : 1.0\n",
    "                dpost1/dt  = -post1/(tc_post_1_ee)     : 1.0\n",
    "                dpost2/dt  = -post2/(tc_post_2_ee)     : 1.0\n",
    "            '''\n",
    "eqs_stdp_pre_ee = 'pre = 1.; w -= nu_ee_pre * post1'\n",
    "eqs_stdp_post_ee = 'post2before = post2; w += nu_ee_post * pre * post2before; post1 = 1.; post2 = 1.'\n",
    "    \n",
    "b.ion()\n",
    "fig_num = 1\n",
    "neuron_groups = {}\n",
    "input_groups = {}\n",
    "connections = {}\n",
    "stdp_methods = {}\n",
    "rate_monitors = {}\n",
    "spike_monitors = {}\n",
    "spike_counters = {}\n",
    "result_monitor = np.zeros((update_interval,n_e))\n",
    "\n",
    "\n",
    "# I simply removed \"compile = True\" and \"freeze=True\" from the parameter lists below \n",
    "neuron_groups['e'] = b.NeuronGroup(n_e*len(population_names), neuron_eqs_e, threshold= v_thresh_e, refractory= refrac_e, reset= scr_e)\n",
    "\n",
    "neuron_groups['i'] = b.NeuronGroup(n_i*len(population_names), neuron_eqs_i, threshold= v_thresh_i, refractory= refrac_i, reset= v_reset_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc34ca24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create neuron group A\n",
      "create recurrent connections\n",
      "(400, 3) ./random/../random/AeAi.npy\n",
      "(160000, 3) ./random/../random/AiAe.npy\n",
      "create monitors for A\n",
      "create connections between X and A\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (2000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m     connections[connName]\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m     67\u001b[0m     connections[connName]\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m weightMatrix\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m---> 68\u001b[0m     connections[connName]\u001b[38;5;241m.\u001b[39mdelay \u001b[38;5;241m=\u001b[39m delay[connType]\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ee_STDP_on:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate STDP for connection\u001b[39m\u001b[38;5;124m'\u001b[39m, name[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mname[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\brian2\\groups\\group.py:433\u001b[0m, in \u001b[0;36mVariableOwner.__setattr__\u001b[1;34m(self, name, val, level)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, val)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    428\u001b[0m     name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__class__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m    430\u001b[0m ):\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# Makes sure that classes can override the \"variables\" mechanism\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;66;03m# with instance/class attributes and properties\u001b[39;00m\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables:\n\u001b[0;32m    435\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[name]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\brian2\\synapses\\synapses.py:1183\u001b[0m, in \u001b[0;36mSynapses._set_delay\u001b[1;34m(self, delay, with_unit)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     reference \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mget_addressable_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre)\n\u001b[1;32m-> 1183\u001b[0m \u001b[43mreference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\brian2\\core\\variables.py:982\u001b[0m, in \u001b[0;36mVariableView.set_item\u001b[1;34m(self, item, value, level, namespace)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    975\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen setting a variable based on a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    976\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex, the value has to be a string or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    977\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    978\u001b[0m         )\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# We do not want to go through code generation for runtime\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_with_index_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_with_expression_conditional(\n\u001b[0;32m    985\u001b[0m         item, \u001b[38;5;28mrepr\u001b[39m(value), check_units\u001b[38;5;241m=\u001b[39mcheck_units, run_namespace\u001b[38;5;241m=\u001b[39mnamespace\n\u001b[0;32m    986\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\brian2\\core\\base.py:335\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\brian2\\core\\variables.py:1325\u001b[0m, in \u001b[0;36mVariableView.set_with_index_array\u001b[1;34m(self, item, value, check_units)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(q\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(q) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(q) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(indices):\n\u001b[0;32m   1320\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1321\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided values do not match the size \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1322\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the indices, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1323\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(q)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m             )\n\u001b[1;32m-> 1325\u001b[0m variable\u001b[38;5;241m.\u001b[39mget_value()[indices] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (2000,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------ \n",
    "# create network population and recurrent connections\n",
    "#------------------------------------------------------------------------------ \n",
    "for name in population_names:\n",
    "    print('create neuron group', name)\n",
    "    \n",
    "    neuron_groups[name+'e'] = neuron_groups['e'][:n_e]\n",
    "    neuron_groups[name+'i'] = neuron_groups['i'][:n_i]\n",
    "    \n",
    "    neuron_groups[name+'e'].v = v_rest_e - 40. * b.mV\n",
    "    neuron_groups[name+'i'].v = v_rest_i - 40. * b.mV\n",
    "    if test_mode or weight_path[-8:] == 'weights/':\n",
    "        neuron_groups['e'].theta = np.load(weight_path + 'theta_' + name + ending + '.npy')\n",
    "    else:\n",
    "        neuron_groups['e'].theta = np.ones((n_e)) * 20.0*b.mV\n",
    "    \n",
    "    print('create recurrent connections')\n",
    "    for conn_type in recurrent_conn_names:\n",
    "        connName = name+conn_type[0]+name+conn_type[1]\n",
    "        weightMatrix = get_matrix_from_file(weight_path + '../random/' + connName + ending + '.npy')\n",
    "        connections[connName] = b.Synapses(neuron_groups[connName[0:2]], neuron_groups[connName[2:4]], 'w : 1', on_pre= 'g'+conn_type[0]+'+=w')\n",
    "        connections[connName].connect()\n",
    "        connections[connName].w = weightMatrix.flatten()\n",
    "                \n",
    "    if ee_STDP_on:\n",
    "        if 'ee' in recurrent_conn_names:\n",
    "            stdp_methods[name+'e'+name+'e'] = b.STDP(connections[name+'e'+name+'e'], eqs=eqs_stdp_ee, pre = eqs_stdp_pre_ee, \n",
    "                                                           post = eqs_stdp_post_ee, wmin=0., wmax= wmax_ee)\n",
    "\n",
    "    print('create monitors for', name)\n",
    "    rate_monitors[name+'e'] = b.PopulationRateMonitor(neuron_groups[name+'e']) #Used to have the following depracated parameter: bin = (single_example_time+resting_time)/b.second\n",
    "    rate_monitors[name+'i'] = b.PopulationRateMonitor(neuron_groups[name+'i'])\n",
    "    spike_counters[name+'e'] = b.SpikeMonitor(neuron_groups[name+'e'])\n",
    "    \n",
    "    if record_spikes:\n",
    "        spike_monitors[name+'e'] = b.SpikeMonitor(neuron_groups[name+'e'])\n",
    "        spike_monitors[name+'i'] = b.SpikeMonitor(neuron_groups[name+'i'])\n",
    "\n",
    "if record_spikes:\n",
    "    b.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    b.ion()\n",
    "    b.subplot(211)\n",
    "    brian_plot(spike_monitors['Ae']) # Depracated parameters for b.raster_plot which used to lie here: refresh=1000*b.ms, showlast=1000*b.ms\n",
    "    b.subplot(212)\n",
    "    brian_plot(spike_monitors['Ai'])\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# create input population and connections from input populations \n",
    "#------------------------------------------------------------------------------ \n",
    "pop_values = [0,0,0]\n",
    "for i,name in enumerate(input_population_names):\n",
    "    input_groups[name+'e'] = b.PoissonGroup(n_input, 0*Hz)\n",
    "    rate_monitors[name+'e'] = b.PopulationRateMonitor(input_groups[name+'e']) #  bin = (single_example_time+resting_time)/b.second\n",
    "\n",
    "for name in input_connection_names:\n",
    "    print('create connections between', name[0], 'and', name[1])\n",
    "    for connType in input_conn_names:\n",
    "        connName = name[0] + connType[0] + name[1] + connType[1]\n",
    "        ### The weightMatrix is just totally random for me rn. Therefore, I will replace the below weightMatrix with just np.rand\n",
    "        # weightMatrix = get_matrix_from_file(weight_path + connName + ending + '.npy')\n",
    "        weightMatrix = np.random.rand(n_input, n_e)\n",
    "        connections[connName] = b.Synapses(input_groups[connName[0:2]], neuron_groups[connName[2:4]], 'w : 1', on_pre= 'g'+conn_type[0]+'+=w')\n",
    "        # this is depracated from brian1, I'm not sure what it does so I'm leaving it here for later reference max_delay=delay[connType][1])\n",
    "        connections[connName].connect()\n",
    "        connections[connName].w = weightMatrix.flatten()\n",
    "        connections[connName].delay = delay[connType]\n",
    "    if ee_STDP_on:\n",
    "        print('create STDP for connection', name[0]+'e'+name[1]+'e')\n",
    "        stdp_methods[name[0]+'e'+name[1]+'e'] = b.STDP(connections[name[0]+'e'+name[1]+'e'], eqs=eqs_stdp_ee, pre = eqs_stdp_pre_ee, \n",
    "                                                       post = eqs_stdp_post_ee, wmin=0., wmax= wmax_ee)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# run the simulation and set inputs\n",
    "#------------------------------------------------------------------------------ \n",
    "previous_spike_count = np.zeros(n_e)\n",
    "assignments = np.zeros(n_e)\n",
    "input_numbers = [0] * num_examples\n",
    "outputNumbers = np.zeros((num_examples, 10))\n",
    "if not test_mode:\n",
    "    input_weight_monitor, fig_weights = plot_2d_input_weights()\n",
    "    fig_num += 1\n",
    "if do_plot_performance:\n",
    "    performance_monitor, performance, fig_num, fig_performance = plot_performance(fig_num)\n",
    "for i,name in enumerate(input_population_names):\n",
    "    input_groups[name+'e'].rate = 0\n",
    "b.run(0)\n",
    "j = 0\n",
    "while j < (int(num_examples)):\n",
    "    if test_mode:\n",
    "        if use_testing_set:\n",
    "            rates = testing['x'][j%100,:,:].reshape((n_input)) *  input_intensity\n",
    "        else:\n",
    "            rates = training['x'][j%494,:,:].reshape((n_input)) *  input_intensity\n",
    "    else:\n",
    "        normalize_weights()\n",
    "        rates = training['x'][j%494,:,:].reshape((n_input)) *  input_intensity\n",
    "    input_groups['Xe'].rate = rates\n",
    "#     print('run number:', j+1, 'of', int(num_examples))\n",
    "    b.run(single_example_time, report='text')\n",
    "            \n",
    "    if j % update_interval == 0 and j > 0:\n",
    "        assignments = get_new_assignments(result_monitor[:], input_numbers[j-update_interval : j])\n",
    "    if j % weight_update_interval == 0 and not test_mode:\n",
    "        update_2d_input_weights(input_weight_monitor, fig_weights)\n",
    "    if j % save_connections_interval == 0 and j > 0 and not test_mode:\n",
    "        save_connections(str(j))\n",
    "        save_theta(str(j))\n",
    "    \n",
    "    current_spike_count = np.asarray(spike_counters['Ae'].count[:]) - previous_spike_count\n",
    "    previous_spike_count = np.copy(spike_counters['Ae'].count[:])\n",
    "    if np.sum(current_spike_count) < 5:\n",
    "        input_intensity += 1\n",
    "        for i,name in enumerate(input_population_names):\n",
    "            input_groups[name+'e'].rate = 0\n",
    "        b.run(resting_time)\n",
    "    else:\n",
    "        result_monitor[j%update_interval,:] = current_spike_count\n",
    "        if test_mode and use_testing_set:\n",
    "            input_numbers[j] = testing['y'][j%100][0]\n",
    "        else:\n",
    "            input_numbers[j] = training['y'][j%494][0]\n",
    "        outputNumbers[j,:] = get_recognized_number_ranking(assignments, result_monitor[j%update_interval,:])\n",
    "        if j % 100 == 0 and j > 0:\n",
    "            print('runs done:', j, 'of', int(num_examples))\n",
    "        if j % update_interval == 0 and j > 0:\n",
    "            if do_plot_performance:\n",
    "                unused, performance = update_performance_plot(performance_monitor, performance, j, fig_performance)\n",
    "                print('Classification performance', performance[:(j/float(update_interval))+1])\n",
    "        for i,name in enumerate(input_population_names):\n",
    "            input_groups[name+'e'].rate = 0\n",
    "        b.run(resting_time)\n",
    "        input_intensity = start_input_intensity\n",
    "        j += 1\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# save results\n",
    "#------------------------------------------------------------------------------ \n",
    "print('save results')\n",
    "if not test_mode:\n",
    "    save_theta()\n",
    "if not test_mode:\n",
    "    save_connections()\n",
    "else:\n",
    "    np.save(data_path + 'activity/resultPopVecs' + str(num_examples), result_monitor)\n",
    "    np.save(data_path + 'activity/inputNumbers' + str(num_examples), input_numbers)\n",
    "    \n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# plot results\n",
    "#------------------------------------------------------------------------------ \n",
    "if rate_monitors:\n",
    "    b.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    for i, name in enumerate(rate_monitors):\n",
    "        b.subplot(len(rate_monitors), 1, i)\n",
    "        b.plot(rate_monitors[name].times/b.second, rate_monitors[name].rate, '.')\n",
    "        b.title('Rates of population ' + name)\n",
    "    \n",
    "if spike_monitors:\n",
    "    b.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    for i, name in enumerate(spike_monitors):\n",
    "        b.subplot(len(spike_monitors), 1, i)\n",
    "        b.raster_plot(spike_monitors[name])\n",
    "        b.title('Spikes of population ' + name)\n",
    "        \n",
    "if spike_counters:\n",
    "    b.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    for i, name in enumerate(spike_counters):\n",
    "        b.subplot(len(spike_counters), 1, i)\n",
    "        b.plot(spike_counters['Ae'].count[:])\n",
    "        b.title('Spike count of population ' + name)\n",
    "\n",
    "plot_2d_input_weights()\n",
    "b.ioff()\n",
    "b.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EVALUATOR file, note to self, figure all this after figuring the first part\n",
    "\n",
    "\n",
    "import brian as b\n",
    "from brian import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cmap\n",
    "import time\n",
    "import os.path\n",
    "import scipy \n",
    "import cPickle as pickle\n",
    "from struct import unpack\n",
    "import brian.experimental.realtime_monitor as rltmMon\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# functions\n",
    "#------------------------------------------------------------------------------     \n",
    "def get_labeled_data(picklename, bTrain = True):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('%s.pickle' % picklename):\n",
    "        data = pickle.load(open('%s.pickle' % picklename))\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode\n",
    "        if bTrain:\n",
    "            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        for i in xrange(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in xrange(cols)]  for unused_row in xrange(rows) ]\n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(\"%s.pickle\" % picklename, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def get_recognized_number_ranking(assignments, spike_rates):\n",
    "    summed_rates = [0] * 10\n",
    "    num_assignments = [0] * 10\n",
    "    for i in xrange(10):\n",
    "        num_assignments[i] = len(np.where(assignments == i)[0])\n",
    "        if num_assignments[i] > 0:\n",
    "            summed_rates[i] = np.sum(spike_rates[assignments == i]) / num_assignments[i]\n",
    "    return np.argsort(summed_rates)[::-1]\n",
    "\n",
    "def get_new_assignments(result_monitor, input_numbers):\n",
    "    print result_monitor.shape\n",
    "    assignments = np.ones(n_e) * -1 # initialize them as not assigned\n",
    "    input_nums = np.asarray(input_numbers)\n",
    "    maximum_rate = [0] * n_e    \n",
    "    for j in xrange(10):\n",
    "        num_inputs = len(np.where(input_nums == j)[0])\n",
    "        if num_inputs > 0:\n",
    "            rate = np.sum(result_monitor[input_nums == j], axis = 0) / num_inputs\n",
    "        for i in xrange(n_e):\n",
    "            if rate[i] > maximum_rate[i]:\n",
    "                maximum_rate[i] = rate[i]\n",
    "                assignments[i] = j \n",
    "    return assignments\n",
    "\n",
    "MNIST_data_path = './'\n",
    "data_path = './activity/'\n",
    "training_ending = '100'\n",
    "testing_ending = '100'\n",
    "start_time_training = 0\n",
    "end_time_training = int(training_ending)\n",
    "start_time_testing = 0\n",
    "end_time_testing = int(testing_ending)\n",
    "\n",
    "n_e = 400\n",
    "n_input = 784\n",
    "ending = ''\n",
    "\n",
    "print 'load MNIST'\n",
    "training = get_labeled_data(MNIST_data_path + 'training')\n",
    "testing = get_labeled_data(MNIST_data_path + 'testing', bTrain = False)\n",
    "\n",
    "print 'load results'\n",
    "training_result_monitor = np.load(data_path + 'resultPopVecs' + training_ending + ending + '.npy')\n",
    "training_input_numbers = np.load(data_path + 'inputNumbers' + training_ending + '.npy')\n",
    "testing_result_monitor = np.load(data_path + 'resultPopVecs' + testing_ending + '.npy')\n",
    "testing_input_numbers = np.load(data_path + 'inputNumbers' + testing_ending + '.npy')\n",
    "print training_result_monitor.shape\n",
    "\n",
    "print 'get assignments'\n",
    "test_results = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_max = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_top = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_fixed = np.zeros((10, end_time_testing-start_time_testing))\n",
    "assignments = get_new_assignments(training_result_monitor[start_time_training:end_time_training], \n",
    "                                  training_input_numbers[start_time_training:end_time_training])\n",
    "print assignments\n",
    "counter = 0 \n",
    "num_tests = end_time_testing / 100\n",
    "sum_accurracy = [0] * num_tests\n",
    "while (counter < num_tests):\n",
    "    end_time = min(end_time_testing, 100*(counter+1))\n",
    "    start_time = 100*counter\n",
    "    test_results = np.zeros((10, end_time-start_time))\n",
    "    print 'calculate accuracy for sum'\n",
    "    for i in xrange(end_time - start_time):\n",
    "        test_results[:,i] = get_recognized_number_ranking(assignments, \n",
    "                                                          testing_result_monitor[i+start_time,:])\n",
    "    difference = test_results[0,:] - testing_input_numbers[start_time:end_time]\n",
    "    correct = len(np.where(difference == 0)[0])\n",
    "    incorrect = np.where(difference != 0)[0]\n",
    "    sum_accurracy[counter] = correct/float(end_time-start_time) * 100\n",
    "    print 'Sum response - accuracy: ', sum_accurracy[counter], ' num incorrect: ', len(incorrect)\n",
    "    counter += 1\n",
    "print 'Sum response - accuracy --> mean: ', np.mean(sum_accurracy),  '--> standard deviation: ', np.std(sum_accurracy)\n",
    "\n",
    "\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random connection generating file\n",
    "'''\n",
    "Created on 15.12.2014\n",
    "\n",
    "@author: Peter U. Diehl\n",
    "'''\n",
    "\n",
    "import scipy.ndimage as sp\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "\n",
    "def randomDelay(minDelay, maxDelay):\n",
    "    return np.random.rand()*(maxDelay-minDelay) + minDelay\n",
    "        \n",
    "        \n",
    "def computePopVector(popArray):\n",
    "    size = len(popArray)\n",
    "    complex_unit_roots = np.array([np.exp(1j*(2*np.pi/size)*cur_pos) for cur_pos in xrange(size)])\n",
    "    cur_pos = (np.angle(np.sum(popArray * complex_unit_roots)) % (2*np.pi)) / (2*np.pi)\n",
    "    return cur_pos\n",
    "\n",
    "        \n",
    "def sparsenMatrix(baseMatrix, pConn):\n",
    "    weightMatrix = np.zeros(baseMatrix.shape)\n",
    "    numWeights = 0\n",
    "    numTargetWeights = baseMatrix.shape[0] * baseMatrix.shape[1] * pConn\n",
    "    weightList = [0]*int(numTargetWeights)\n",
    "    while numWeights < numTargetWeights:\n",
    "        idx = (np.int32(np.random.rand()*baseMatrix.shape[0]), np.int32(np.random.rand()*baseMatrix.shape[1]))\n",
    "        if not (weightMatrix[idx]):\n",
    "            weightMatrix[idx] = baseMatrix[idx]\n",
    "            weightList[numWeights] = (idx[0], idx[1], baseMatrix[idx])\n",
    "            numWeights += 1\n",
    "    return weightMatrix, weightList\n",
    "        \n",
    "    \n",
    "def create_weights():\n",
    "    \n",
    "    nInput = 784\n",
    "    nE = 400\n",
    "    nI = nE \n",
    "    dataPath = './random/'\n",
    "    weight = {}\n",
    "    weight['ee_input'] = 0.3 \n",
    "    weight['ei_input'] = 0.2 \n",
    "    weight['ee'] = 0.1\n",
    "    weight['ei'] = 10.4\n",
    "    weight['ie'] = 17.0\n",
    "    weight['ii'] = 0.4\n",
    "    pConn = {}\n",
    "    pConn['ee_input'] = 1.0 \n",
    "    pConn['ei_input'] = 0.1 \n",
    "    pConn['ee'] = 1.0\n",
    "    pConn['ei'] = 0.0025\n",
    "    pConn['ie'] = 0.9\n",
    "    pConn['ii'] = 0.1\n",
    "    \n",
    "    \n",
    "    print 'create random connection matrices'\n",
    "    connNameList = ['XeAe']\n",
    "    for name in connNameList:\n",
    "        weightMatrix = np.random.random((nInput, nE)) + 0.01\n",
    "        weightMatrix *= weight['ee_input']\n",
    "        if pConn['ee_input'] < 1.0:\n",
    "            weightMatrix, weightList = sparsenMatrix(weightMatrix, pConn['ee_input'])\n",
    "        else:\n",
    "            weightList = [(i, j, weightMatrix[i,j]) for j in xrange(nE) for i in xrange(nInput)]\n",
    "        np.save(dataPath+name, weightList)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print 'create connection matrices from E->I which are purely random'\n",
    "    connNameList = ['XeAi']\n",
    "    for name in connNameList:\n",
    "        weightMatrix = np.random.random((nInput, nI))\n",
    "        weightMatrix *= weight['ei_input']\n",
    "        weightMatrix, weightList = sparsenMatrix(weightMatrix, pConn['ei_input'])\n",
    "        print 'save connection matrix', name\n",
    "        np.save(dataPath+name, weightList)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print 'create connection matrices from E->I which are purely random'\n",
    "    connNameList = ['AeAi']\n",
    "    for name in connNameList:\n",
    "        if nE == nI:\n",
    "            weightList = [(i, i, weight['ei']) for i in xrange(nE)]\n",
    "        else:\n",
    "            weightMatrix = np.random.random((nE, nI))\n",
    "            weightMatrix *= weight['ei']\n",
    "            weightMatrix, weightList = sparsenMatrix(weightMatrix, pConn['ei'])\n",
    "        print 'save connection matrix', name\n",
    "        np.save(dataPath+name, weightList)\n",
    "        \n",
    "        \n",
    "        \n",
    "    print 'create connection matrices from I->E which are purely random'\n",
    "    connNameList = ['AiAe']\n",
    "    for name in connNameList:\n",
    "        if nE == nI:\n",
    "            weightMatrix = np.ones((nI, nE))\n",
    "            weightMatrix *= weight['ie']\n",
    "            for i in xrange(nI):\n",
    "                weightMatrix[i,i] = 0\n",
    "            weightList = [(i, j, weightMatrix[i,j]) for i in xrange(nI) for j in xrange(nE)]\n",
    "        else:\n",
    "            weightMatrix = np.random.random((nI, nE))\n",
    "            weightMatrix *= weight['ie']\n",
    "            weightMatrix, weightList = sparsenMatrix(weightMatrix, pConn['ie'])\n",
    "        print 'save connection matrix', name\n",
    "        np.save(dataPath+name, weightList)\n",
    "    \n",
    "         \n",
    "if __name__ == \"__main__\":\n",
    "    create_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
